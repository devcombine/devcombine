name: Run Crawler
on:
  push:
    branches: [ "feat/prgrmcrawltest" ] 
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    - name: Create virtual environment and activate
      run: |
        python -m venv venv
        source venv/bin/activate        
    - name: Install Dependencies
      run: |
        venv/bin/pip install -r requirements.txt
    - name: Download Chrome
      run: |
        sudo apt update
        sudo apt install wget
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo dpkg -i google-chrome-stable_current_amd64.deb
        sudo apt-get install -f
    - name: Install Chromedriver
      run: |
        wget https://chromedriver.storage.googleapis.com/92.0.4515.107/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/bin/chromedriver
        sudo chown root:root /usr/bin/chromedriver
        sudo chmod +x /usr/bin/chromedriver
    - name: Crawl and save to DB
      env:
        SECRET_KEY: ${{ secrets.SECRET_KEY }}
        REMOTE_DB_PASSWORD: ${{ secrets.REMOTE_DB_PASSWORD }}
      run: |
        venv/bin/python crawling.py
